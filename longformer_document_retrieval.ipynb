{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "longformer document retrieval.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYQdlRW100TWoQsBsSzBZ8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarahsultan/joelnet/blob/master/longformer_document_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2DvtLW4fYp8"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwqC9IvGfZZQ"
      },
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ihmkrk2vfZcB",
        "outputId": "bf4da4b7-9483-4815-e10d-d0fee8d8f597"
      },
      "source": [
        "!mkdir folderOnColab\n",
        "!gcsfuse rokin-articles folderOnColab"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021/06/01 10:30:23.147315 Using mount point: /content/folderOnColab\n",
            "2021/06/01 10:30:23.155198 Opening GCS connection...\n",
            "2021/06/01 10:30:23.701073 Mounting file system \"rokin-articles\"...\n",
            "2021/06/01 10:30:23.741715 File system has been successfully mounted.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn8u5HawfZeh"
      },
      "source": [
        "import pandas as pd\n",
        "cleaned = pd.read_json(\"/content/folderOnColab/from_2017_dataset_english.json.gz\",\n",
        "                       compression=\"gzip\",\n",
        "                       orient=\"records\",\n",
        "                       lines=True)\n",
        "cleaned = cleaned.values.flatten()\n",
        "cleaned = cleaned[cleaned!=None]\n",
        "cleaned = pd.DataFrame.from_records(cleaned)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCF89FmLfZhR"
      },
      "source": [
        "# remove articles of nature.com\n",
        "cleaned = cleaned[cleaned.sitename != 'nature.com']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_kPZcEafZjR"
      },
      "source": [
        "# articles text in a list\n",
        "article_text  = []  # each item of this list is a string which is one article\n",
        "for index, row in cleaned.iterrows():\n",
        "    sample_txt = row['text']\n",
        "    article_text.append(sample_txt)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0mw9jl4fZoB",
        "outputId": "639f3cbb-c10a-441c-ea7c-632319a5a8bf"
      },
      "source": [
        "len(article_text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "554020"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqsXWnI8xm81"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHioJTSQyq1E"
      },
      "source": [
        "pip install transformers faiss torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMDnzCgXyqyz"
      },
      "source": [
        "!apt install libomp-dev\n",
        "!python -m pip install --upgrade faiss faiss-gpu\n",
        "import faiss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "185GZRNtxGgU"
      },
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
        "model = AutoModel.from_pretrained(\"allenai/longformer-base-4096\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWHqRdHGyqwa"
      },
      "source": [
        "documents = article_text[0:110]\n",
        "\n",
        "vectors = [\n",
        "  # tokenize the document, return it as PyTorch tensors (vectors),\n",
        "  # and pass it onto the model\n",
        "  model(**tokenizer(document, return_tensors='pt'))[0].detach().squeeze()\n",
        "  for document in documents\n",
        "]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpIYxZQpy9FU"
      },
      "source": [
        "import torch\n",
        "\n",
        "averaged_vectors = [torch.mean(vector, dim=0) for vector in vectors]\n",
        "\n",
        "[v.size() for v in averaged_vectors]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKwtCjZBy_0h"
      },
      "source": [
        "def encode(document: str) -> torch.Tensor:\n",
        "  tokens = tokenizer(document, return_tensors='pt')\n",
        "  vector = model(**tokens)[0].detach().squeeze()\n",
        "  return torch.mean(vector, dim=0)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwZImdB8zB39"
      },
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "index = faiss.IndexIDMap(faiss.IndexFlatIP(768)) # the size of our vector space\n",
        "# index all the documents, we need them as numpy arrays first\n",
        "index.add_with_ids(\n",
        "    np.array([t.numpy() for t in averaged_vectors]),\n",
        "    # the IDs will be 0 to len(documents)\n",
        "    np.array(range(0, len(documents)))\n",
        ")\n",
        "\n",
        "def search(query: str, k=1):\n",
        "  encoded_query = encode(query).unsqueeze(dim=0).numpy()\n",
        "  top_k = index.search(encoded_query, k)\n",
        "  scores = top_k[0][0]\n",
        "  results = [documents[_id] for _id in top_k[1][0]]\n",
        "  return list(zip(results, scores))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rqv6N18sMMyj",
        "outputId": "cdbbe687-2fd1-4082-d9a0-ab4b8c409a3f"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%install_ext` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03Z8mvukzDuX"
      },
      "source": [
        "%time \n",
        "search(\"virtual reality\", k=5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}