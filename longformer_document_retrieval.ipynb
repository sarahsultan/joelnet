{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "longformer document retrieval.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYQdlRW100TWoQsBsSzBZ8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarahsultan/joelnet/blob/master/longformer_document_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2DvtLW4fYp8"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwqC9IvGfZZQ"
      },
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ihmkrk2vfZcB",
        "outputId": "bf4da4b7-9483-4815-e10d-d0fee8d8f597"
      },
      "source": [
        "!mkdir folderOnColab\n",
        "!gcsfuse rokin-articles folderOnColab"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021/06/01 10:30:23.147315 Using mount point: /content/folderOnColab\n",
            "2021/06/01 10:30:23.155198 Opening GCS connection...\n",
            "2021/06/01 10:30:23.701073 Mounting file system \"rokin-articles\"...\n",
            "2021/06/01 10:30:23.741715 File system has been successfully mounted.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn8u5HawfZeh"
      },
      "source": [
        "import pandas as pd\n",
        "cleaned = pd.read_json(\"/content/folderOnColab/from_2017_dataset_english.json.gz\",\n",
        "                       compression=\"gzip\",\n",
        "                       orient=\"records\",\n",
        "                       lines=True)\n",
        "cleaned = cleaned.values.flatten()\n",
        "cleaned = cleaned[cleaned!=None]\n",
        "cleaned = pd.DataFrame.from_records(cleaned)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCF89FmLfZhR"
      },
      "source": [
        "# remove articles of nature.com\n",
        "cleaned = cleaned[cleaned.sitename != 'nature.com']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_kPZcEafZjR"
      },
      "source": [
        "# articles text in a list\n",
        "article_text  = []  # each item of this list is a string which is one article\n",
        "for index, row in cleaned.iterrows():\n",
        "    sample_txt = row['text']\n",
        "    article_text.append(sample_txt)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0mw9jl4fZoB",
        "outputId": "639f3cbb-c10a-441c-ea7c-632319a5a8bf"
      },
      "source": [
        "len(article_text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "554020"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqsXWnI8xm81"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHioJTSQyq1E"
      },
      "source": [
        "pip install transformers faiss torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMDnzCgXyqyz"
      },
      "source": [
        "!apt install libomp-dev\n",
        "!python -m pip install --upgrade faiss faiss-gpu\n",
        "import faiss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "185GZRNtxGgU"
      },
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
        "model = AutoModel.from_pretrained(\"allenai/longformer-base-4096\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWHqRdHGyqwa"
      },
      "source": [
        "documents = article_text[0:110]\n",
        "\n",
        "vectors = [\n",
        "  # tokenize the document, return it as PyTorch tensors (vectors),\n",
        "  # and pass it onto the model\n",
        "  model(**tokenizer(document, return_tensors='pt'))[0].detach().squeeze()\n",
        "  for document in documents\n",
        "]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpIYxZQpy9FU"
      },
      "source": [
        "import torch\n",
        "\n",
        "averaged_vectors = [torch.mean(vector, dim=0) for vector in vectors]\n",
        "\n",
        "[v.size() for v in averaged_vectors]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKwtCjZBy_0h"
      },
      "source": [
        "def encode(document: str) -> torch.Tensor:\n",
        "  tokens = tokenizer(document, return_tensors='pt')\n",
        "  vector = model(**tokens)[0].detach().squeeze()\n",
        "  return torch.mean(vector, dim=0)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwZImdB8zB39"
      },
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "index = faiss.IndexIDMap(faiss.IndexFlatIP(768)) # the size of our vector space\n",
        "# index all the documents, we need them as numpy arrays first\n",
        "index.add_with_ids(\n",
        "    np.array([t.numpy() for t in averaged_vectors]),\n",
        "    # the IDs will be 0 to len(documents)\n",
        "    np.array(range(0, len(documents)))\n",
        ")\n",
        "\n",
        "def search(query: str, k=1):\n",
        "  encoded_query = encode(query).unsqueeze(dim=0).numpy()\n",
        "  top_k = index.search(encoded_query, k)\n",
        "  scores = top_k[0][0]\n",
        "  results = [documents[_id] for _id in top_k[1][0]]\n",
        "  return list(zip(results, scores))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rqv6N18sMMyj",
        "outputId": "cdbbe687-2fd1-4082-d9a0-ab4b8c409a3f"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%install_ext` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03Z8mvukzDuX",
        "outputId": "65b2ba83-0f79-4b9f-e604-70664c346fe9"
      },
      "source": [
        "%time \n",
        "search(\"virtual reality\", k=5)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 17.9 µs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The design and construction industry contributes massively to any nations economy. Unfortunately, there is one major problem limiting the potential of this industry: communication. While face- to- face meetings are great, its not always easy and efficient, especially when working with widely distributed teams across multiple projects. With the new 360° markups feature from HoloBuilder, this problem is about to become history.\\nThe 360° markups feature allows you to take a virtual tour of your construction site, take notes and pass location- specific instructions. After importing a 3D model into the HoloBuilder web editor, the user- friendly interface makes it easy to draw a markup and highlight specific issues, such as the need for some machinery in a particular location, and communicate these issues to members of the team.\\nOnce a markup is drawn and a comment is made, it becomes automatically included in the 360° MarkupList. This is where all images and comments can be tracked, showing why and when a markup was added and by whom. The MarkupList can be accessed by all project collaborators in real- time, making it easy for the relevant party to take the required action.\\nThis feature is a great tool for seamless and efficient team collaboration and may very well reshape the future of design and construction. Ensuring the same data is available online to project participants helps keep all collaborators on the same page without the need for physical proximity.\\nIt is also a great way of reporting ongoing activities on- site. If youd like to know if a new door has been delivered and installed, all you have to do is go on a virtual walk to that section- while never leaving your desk. This, of course, can help save transportation costs, among other things.\\nAdditional benefits of the 360° markups feature include the ability to estimate project outcomes and required materials. The system uses existing data in the framework, including markups, to make calculations about the amount of material still required for project completion. For example, the system can estimate how many more doors need to be ordered and installed in order to meet project goals. This can save a great deal of time and prevent the all- too- common wastage associated with ordering excessive materials.\\nWithout a doubt, the design and construction industry could use more practical applications of HoloLens. The HoloBuilder 360° markups feature might just be the next big thing in the industry. More information about this feature can be found in HoloBuilders comprehensive tutorial.',\n",
              "  150.54243),\n",
              " ('NASA rovers have provided a detailed glimpse of the Mars surface. Study of the neighboring planet continues, but humans are still nowhere near making the red planet a habitable destination. That doesnt mean technologies and expertise cant be combined to create a realistic experience of what living on Mars could be like.\\nHP and NVIDIA have partnered to make a virtual reality (VR) tour of Mars real. At the 2018 SIGGRAPH conference, HP unveiled the results of the yearlong project, HP Mars Home Planet. The unique program brought together more than 90,000 creative and scientific professionals across a range of industries and countries to contribute their ideas of what 1 million humans living on a utopian Mars might be like.\\nWe are living in interesting times when technological advancement is being met by a broad array of foundational space science and planetary research- a confluence that will optimistically serve to accelerate our path toward human exploration and settlement of Mars, said Darlene Lim, principal investigator at NASA Biologic Analog Science. Today, people around the world are dreaming and innovating towards this future, and the amazing entries from the HP Mars Home Planet projects creative community give us a virtual window into what life on Mars could be like for a million members of humanity.\\nThe project had approximately 1,000 submissions for a Concept Challenge and 3D Modeling Challenge. The final phase of the project was selecting nine winners in a Rendering Challenge. The top ideas were then turned into a VR experience thanks to Technicolor, which created visuals for the experience using Epics Unreal Engine.\\nThe ultimate power for fully immersive VR experiences comes from the creative community and the computing process delivered by HP and our partners, said Xavier Garcia, vice president and general manager of Z by HP. HPs technology leadership, rich history of product innovation, and understanding of the creative workflow is bringing amazing ideas to life.\\nThe result, which aired at SIGGRAPH, was the first six- degrees- of- freedom VR piece built for motion- enabled chairs using HP Windows Mixed Reality headsets. The one- of- a- kind experience begins with users entering a Martian Community Onboarding Center that It showcases innovations in architecture, engineering and transportation that could enable humans to live on Mars. A trailer can be watched here.',\n",
              "  149.85838),\n",
              " ('NASAs ambitious plan to send humans to Mars in the 2030s is certainly exciting- but a lot needs to be done to make that happen. One critical factor for success is ensuring that there will be a strong and skilled workforce of engineers and scientists to help get us there.\\nEnter Generation Beyond, an ambitious program launched by Lockheed Martin in 2016, which aims to build and train the workforce that will be needed for deep space exploration by getting the nations future engineers hooked on STEM while theyre still young.\\nThink about this, said Gary Napier from Lockheed Martin. The first astronaut to step foot on Mars - she is in school right now, in middle school or elementary school, and we want to inspire her, to really grab her attention to say, Its possible. It can be you.\\nENGINEERING.com visited Napier in the Lockheed Martin booth at the USA Science and Engineering Festival, where he shared the goals of Generation Beyond and its centerpiece, the Mars Experience Bus.\\nGeneration Beyond is a cool initiative that inspires kids about STEM- science, technology, engineering and math- using deep space exploration and the allure of going to Mars, Napier explained.\\nThe Mars Experience Bus is a key component of this strategy, featuring a school bus outfitted with screens and a sound system that offers young students a taste of the future with a virtual reality tour across the Martian surface.\\nOnce the kids get in, the windows transform and its the Martian landscape. We worked with the same guys who did The Martian movie, and now we are driving this bus down the road and the kids can see the Martian landscape moving by, we see the Curiosity Rover, we see a futuristic Mars base. Its just a cool, immersive virtual reality experience, Napier said.\\nThe Generation Beyond initiative also offers resources and curriculum materials for teachers and parents to teach STEM subjects using deep space exploration topics. The initiative also created an app called Hello Mars, which allows students to explore information about Mars and even get weather and temperature reports.\\nThe goal is to get these kids into STEM early in their lives so that they will pursue higher education and careers in the future tech workforce.\\nWe are absolutely going to need a huge number of engineers and scientists in our future. Were always bringing in more young, new talent, so we want those kids who are just stoked about science and exploration and space to come and work for us. We want them for the technology economy that we have in the United States and around the world, so its paramount that we get these kids really excited about engineering and math, Napier added.',\n",
              "  149.40909),\n",
              " ('While augmented reality (AR) and virtual reality (VR) can be traced all the way back to the 1950s and 1960s and Morton Heilig- now often referred to as the father of virtual reality- these technologies have only recently made their way into the architecture, engineering and construction (AEC) industry. The high cost of software applications, equipment and training, along with a lack of expertise, are a few of the factors contributing to the slow adoption of AR and VR in AEC.\\nIn addition to the factors already mentioned, many companies find it difficult to implement AR and VR due to the vast number of choices combined with the low availability of unbiased and detailed information about available AR and VR options. Finding the best fit of software and equipment for a given application can be extremely difficult, not to mention the subsequent challenge of justifying return on investment (ROI). The best AR or VR solution wont do much good if it negatively affects profitability.\\nAniwaa is working to change all that. Thanks to a recent round of funding, the startup has built what it considers the most complete database yet, which is devoted to virtual, augmented and mixed reality head- mounted displays (HMDs). Aniwaa also just announced a major update to its website and branding. Founded in 2013 and headquartered in Singapore, Aniwaa provides information about emerging technologies such as 3D printing, 3D scanning, and virtual and augmented reality. Its goal is to help those interested in these technologies find the right products by providing the information and guidance needed for consumers to make informed decisions about them. Aniwaa is able to accomplish this by providing comparison tools, in- depth articles and product reviews.\\nThe company has even developed its own rating system, called a metascore, and which is meant to provide a fair and balanced assessment of the products it covers. The metascore is an index based on ratings from trusted sources, as well as fair and unbiased evaluations of these hardware products. Aniwaa also tests and reviews all the products in- house and follows its own independent testing protocol to make the process as fair and balanced as possible. Its website states that Because researching and comparing the latest tech devices can be a daunting task, we do the heavy lifting for our users so they can focus on what really matters: choosing the best product.\\nThere are many overlaps between VR/AR and 3D printing, so it was a logical choice for us, commented Pierre- Antoine Arrighi, Aniwaas cofounder and technical advisor. New hardware is being announced almost every week now, which is great, but its also creating a very fragmented space. The number of headsets more than doubled since we started discussing this project at the beginning of the year, and this is where we can make a difference.\\nThe Aniwaa product database currently includes 1,400 3D printers, 250 3D scanners, and over 100 VR/AR headsets- numbers that are growing all the time. The database allows potential AR and VR consumers to compare hundreds of VR headsets and AR glasses with Aniwaas comparison engines, while at the same time, they can gather more information from unbiased and in- depth product reviews. Aniwaa also has guides that can help users navigate these complex emerging technologies so that they can understand the products different applications and make the best choices based on their needs and budget.\\nAniwaas website and comparison engine will potentially be a big help to those in the AEC industry looking to adopt and implement AR and VR solutions. The site covers all extended reality categories (virtual, mixed and augmented): tethered (or PC) VR, stand- alone VR, smartphone VR, mixed reality headsets and AR glasses (smart glasses), enabling users to search and compare by price, technology, technical specs, reviews and ratings. Being able to easily compare multiple options while evaluating ROI potential will allow companies to make the best choices based on applications and budgets.',\n",
              "  149.14839),\n",
              " ('The 3rd Annual Medical Capital Innovation Competition has been set for April 17 and April 18 at Clevelands Global Center for Health Innovation. This years theme is AR/VR/XR: The New Reality of Healthcare.\\nThe symposium will allow participants a chance to discuss how virtual reality, augmented reality and cross- reality technologies can engage doctors and patients, bringing healthcare to even higher levels.\\n$100,000 in award money, as well as co- development and mentoring opportunities, will be offered to worldwide AR/VR/XR startups in collegiate and professionals divisions. Applications began being accepted Jan. 14 and will continue to be accepted until March 15.\\nBioEnterprise CEO and President Aram Nerpouni said both virtual reality and augmented reality are changing many industries including education, IT, marketing and retail. Healthcare, he said, is the next step for these technologies. Nerpouni said the competition provides these startup companies to get access to tools that can assist them in coming up with innovative methods to better both the care and experience of patients.\\nBioEnterpise puts on the two- day business plan pitch competition each year, allowing teams a chance to showcase their technologies to a panel of expert judges. Industry experts will judge them based on certain criteria that include team strength, technical viability and others. In 2018, there were 180 applicant teams from 33 states and 24 countries - some hailed from Carnegie Mellon University, Johns Hopkins University and Western Reserve University.\\nIn 2017, there were nearly 650 AR and VR companies with a small amount of healthcare clientele. In the last 10 years, there have been about 140 AR/VR/XR deals for the healthcare industry with about $5 billion invested. Most of the deals have taken place in the last five years, which is a 1,000 percent increase in that timeframe. The current AR and VR healthcare related applications are found for mental health conditions like anxiety, dementia, PTSD and phobias, pain management, digital diagnostics, patient education, and surgical training and guidance.\\nThe Medical Capital Innovation Competition is supported by numerous entities including but not limited to: Healthcare Information and Management Systems Society, JumpStart, Cleveland Clinic Innovations, MetroHealth Systems, ProMedica and Cuyahoga County.',\n",
              "  149.02547)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    }
  ]
}